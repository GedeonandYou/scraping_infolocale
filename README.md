# Infolocale Scraper

Syst√®me complet de scraping et d'API REST pour collecter et exposer les √©v√©nements du site [infolocale.fr](https://www.infolocale.fr)

## Description

Ce projet automatise la collecte d'√©v√©nements locaux depuis Infolocale et expose les donn√©es via une API REST. Il inclut un scraper Selenium avec g√©ocodage automatique (OpenRouteService) et une base de donn√©es PostgreSQL.

## ‚ö° D√©marrage rapide

# 1. Cloner le projet

git clone `<repo-url>`
cd scraping_infolocale

## üõ†Ô∏è Technologies

- **Backend**: FastAPI (Python 3.11)
- **Scraping**: Selenium + ChromeDriver
- **Base de donn√©es**: PostgreSQL 15
- **G√©ocodage**: OpenRouteService API
- **Frontend**: React + TypeScript + Vite
- **Conteneurisation**: Docker + Docker Compose

**En local**:

```bash
# Backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
python main.py api

# Frontend
cd frontend
npm install
npm run dev
```

## üöÄ Utilisation

### Commandes CLI

```bash
# Scraper des √©v√©nements
python main.py scrape --max-pages 10

# Lancer l'API
python main.py api

# Scraper sans g√©ocodage (plus rapide)
python main.py scrape --no-geocode --max-pages 20

# Voir l'aide
python main.py --help
```

### API Endpoints

**Documentation interactive**: `http://localhost:8000/docs`

**Principaux endpoints**:

- `GET /events` - Liste tous les √©v√©nements
- `GET /events/{id}` - D√©tails d'un √©v√©nement
- `GET /events/search?city=Paris` - Recherche par ville
- `GET /health` - Status de l'API

### G√©ocodage

Le projet utilise OpenRouteService avec respect des rate limits:

- D√©lai de 2 secondes entre requ√™tes (30 req/min)
- G√©ocodage automatique pendant le scraping
- Script batch pour g√©ocoder r√©troactivement: `info-dev/geocode_missing_events.py`

### Scraping

Le scraper respecte automatiquement:

- D√©tection des doublons (via `data-id`)
- Gestion de la pagination
- Rate limiting du g√©ocodage
- Headless Chrome via Selenium
